{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams['figure.figsize'] = [5, 5]\n",
    "matplotlib.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import cv2\n",
    "#from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "\n",
    "from data_helper import UnlabeledDataset, LabeledDataset\n",
    "from helper import collate_fn, draw_box, compute_ts_road_map\n",
    "from darknet import *\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### helper functions ##########\n",
    "\n",
    "\n",
    "def sew_images(sing_samp):\n",
    "        # sing_samp is [6, 3, 256, 306], one item is batch\n",
    "        # output is the image object of all 6 pictures 'sown' together\n",
    "        #############\n",
    "        # A | B | C #\n",
    "        # D | E | F #\n",
    "        #############\n",
    "        \n",
    "        # return [3, 768, 612]\n",
    "        \n",
    "        A1 = sing_samp[0][0]\n",
    "        A2 = sing_samp[0][1]\n",
    "        A3 = sing_samp[0][2]\n",
    "\n",
    "        B1 = sing_samp[1][0]\n",
    "        B2 = sing_samp[1][1]\n",
    "        B3 = sing_samp[1][2]\n",
    "\n",
    "        C1 = sing_samp[2][0]\n",
    "        C2 = sing_samp[2][1]\n",
    "        C3 = sing_samp[2][1]\n",
    "\n",
    "        D1 = sing_samp[3][0]\n",
    "        D2 = sing_samp[3][1]\n",
    "        D3 = sing_samp[3][2]\n",
    "\n",
    "        E1 = sing_samp[4][0]\n",
    "        E2 = sing_samp[4][1]\n",
    "        E3 = sing_samp[4][2]\n",
    "\n",
    "        F1 = sing_samp[5][0]\n",
    "        F2 = sing_samp[5][1]\n",
    "        F3 = sing_samp[5][2]\n",
    "\n",
    "        #print(\"F shape {}\".format(F1.shape))\n",
    "\n",
    "        T1 = torch.cat([A1, B1, C1], 1)\n",
    "        T2 = torch.cat([A2, B2, C2], 1)\n",
    "        T3 = torch.cat([A3, B3, C3], 1)\n",
    "\n",
    "        B1 = torch.cat([D1, E1, F1], 1)\n",
    "        B2 = torch.cat([D2, E2, F2], 1)\n",
    "        B3 = torch.cat([D3, E3, F3], 1)\n",
    "        #print(\"T1 shape {}\".format(T1.shape))\n",
    "\n",
    "        comb1 = torch.cat([T1,B1], 0)\n",
    "        comb2 = torch.cat([T2,B2], 0)\n",
    "        comb3 = torch.cat([T3,B3], 0)\n",
    "\n",
    "        #print(\"comb1 shape {}\".format(comb1.shape)) #should be 768, 612\n",
    "        comb = torch.stack([comb1, comb2, comb3])\n",
    "        # TODO: maybe should flip and face right\n",
    "        toImg = transforms.ToPILImage()\n",
    "        result = toImg(comb) # image object [3, 768, 612]\n",
    "        return result\n",
    "    \n",
    "############\n",
    "## usage:\n",
    "# image_tensor = torch.stack(images) #should be [6, 3, 256, 306]\n",
    "# m = transforms.Resize((800,800))\n",
    "# comb_img = sew_images(image_tensor) \n",
    "# img =m(comb_img) #should be [3, 800, 800]\n",
    "############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0);\n",
    "\n",
    "image_folder = '../data'\n",
    "annotation_csv = '../data/annotation.csv'\n",
    "\n",
    "labeled_scene_index = np.arange(106, 134)\n",
    "\n",
    "train_index = np.arange(106,108)\n",
    "val_index = np.arange(128,130)\n",
    "transform = torchvision.transforms.ToTensor()\n",
    "\n",
    "labeled_trainset = LabeledDataset(\n",
    "    image_folder=image_folder,\n",
    "    annotation_file=annotation_csv,\n",
    "    scene_index=train_index,\n",
    "    transform=transform,\n",
    "    extra_info=False\n",
    "    )\n",
    "\n",
    "labeled_valset = LabeledDataset(\n",
    "    image_folder=image_folder,\n",
    "    annotation_file=annotation_csv,\n",
    "    scene_index=val_index,\n",
    "    transform=transform,\n",
    "    extra_info=False\n",
    "    )\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(labeled_trainset, batch_size=2, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
    "valloader = torch.utils.data.DataLoader(labeled_valset, batch_size=2, shuffle=True, num_workers=2, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### initialize model ####\n",
    "batch_size = 2\n",
    "confidence = 0.5\n",
    "nms_thesh = 0.4\n",
    "start = 0\n",
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Darknet('yolov3.cfg').to(device)\n",
    "model.net_info[\"height\"] = 800\n",
    "\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "#param_list = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    [{'params': filter(lambda p: p.requires_grad, model.parameters()),\n",
    "    'lr': 0.0001}],\n",
    "    lr=0.0001,\n",
    "    momentum=0.9,\n",
    "    weight_decay=0.0001,\n",
    "    nesterov=False,\n",
    "    )\n",
    "best_val_loss = 100\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit",
   "language": "python",
   "name": "python37764bite090039fc95743639b991c3c7d67a783"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
